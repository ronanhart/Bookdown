[["index.html", "Masters Thesis Research Chapter 1 Masters Thesis Project 1.1 Abstract 1.2 Questions 1.3 Objectives", " Masters Thesis Research Ronan Hart 2021-03-04 Chapter 1 Masters Thesis Project Quantifying the Impacts of Anthropogenic Movement Barriers on Ungulate Space-Use Patterns and Functional Connectivity in Utah 1.1 Abstract Movement is an essential function for large herbivores to acquire resources and to avoid predation risk. The successful execution, and thus the functional value, of movement is dependent on the connectivity of the landscape. Impediments to movement, such as anthropogenic barriers, can impact space-use behaviors and cause functional habitat loss and fragmentation. Disruptions to landscape connectivity can increase mortality, block gene flow, increase a populations vulnerability to extirpation, and compromise metapopulation persistence. Furthermore, because functional landscape connectivity is species- and context-dependent, it is necessary to be scrutinous and examine animal movement by multiple species and in a variety of spatial-temporal contexts to understand the full scope of barrier impacts on functional connectivity. To address this, our research will look at two ungulate species in Utah  mule deer (Odocoileus hemionus) and pronghorn (Antilocapra americana)  that share similar movement patterns and geographic space but require different ecological needs and reside in, and move through, different habitats. These two species provide a unique opportunity to compare their space-use shifts around barriers and therefore gain a holistic understanding of functional habitat loss in the many landscapes across Utah. I will use GPS-collar data provided by the Utah Division of Wildlife Resources (UDWR) to analyze individual movement with respect to roads, fences, landcover, vegetation, and snow depth using integrated step selection analysis (iSSA). I plan to provide a comprehensive picture of landscape connectivity in a variable landscape with multiple species. This will give wildlife managers with essential tools to mitigate current barrier effects and aid in predicting impacts from future barrier construction. 1.2 Questions I seek to answer four main questions Do barriers impact pronghorn differently than they impact mule deer? How do barrier impacts differ between seasons? How do barrier impacts differ between individuals and populations exhibiting different movement patterns? Do barrier impacts vary in different habitat types? 1.3 Objectives Determine the probability of crossing a barrier. I will consider probability to be a function of species, barrier attributes traffic volume, number of lanes, fence type, and fence height), and the local environmental attributes (time of day, season, elevation, vegetation type and quality, and snow depth). Quantify behavioral responses around roads and fences to estimate functional habitat loss due to proximity avoidance. Develop maps showing habitat loss and fragmentation due to barrier impacts. Develop maps of the relative probability of barrier crossing and avoidance given the environmental attributes of each point in the map. Use these maps to determine where and when barriers cause the highest degradation, predict how future barrier construction could impact habitats, and predict how barrier modification could mitigate impacts. "],["db-structure.html", "Chapter 2 Database Structure 2.1 Database Structure 2.2 Forming the Database 2.3 RSQLite", " Chapter 2 Database Structure 2.1 Database Structure To best structure all of my data, I will be storing my datasets into a database. My data will be in 3 main categories: GPS data from collared pronghorn and mule deer Barrier locations and attributes (roads, fences, railroads, etc.) Environmental covariates Elevation Landcover Vegetation type and phenology Snow depth (#fig:dir_pic)Directory Structure The above picture shows my directory structure for this project. This directory reflects an Activity-based organization, with all the code stored in one folder, all the data stored in one folder, etc. (#fig:db_pic)Database Structure The above picture shows my database structure. Most of this database is of the GPS data from collared animals. The majority of data of barriers and environmental covariates will be in the form of shapefiles or rasters, and so were not included in this database structure. 2.2 Forming the Database Before I can begin working in RSQLite, I have to first format my raw data into a structure matching my planned structure above. (#fig:raw_dat_pic)Column Names of Raw Data To format my dataframes, I will be working with the packages dplyr  which allows me to manipulate dataframes  and lubridate  which allows me to work with date and time formats. # Install Packages---- install.packages(&quot;dplyr&quot;) install.packages(&quot;lubridate&quot;) # Load Packages ---- library(dplyr) library(lubridate) 2.2.1 Base Format Note: I want to apologize to seasoned R coders that I come from a python background and I refuse to use &lt;- as an assignment operator (too many keystrokes!). Instead, I use =. # Load Data ---- df = read.csv(&quot;Data/full_data.csv&quot;) Note: For the purposes of this demonstration, I have subset my data and randomized certain elements Lets take a look at the data head(df) ## X collarObjectId species dateYearAndJulian collarID uniqueID mortality ## 1 1 171976 mule deer 2014-12-08 02:00:00 34895 MD13F0035 false ## 2 2 171977 mule deer 2014-12-08 14:00:00 34895 MD13F0035 false ## 3 3 171978 mule deer 2014-12-09 15:00:00 34895 MD13F0035 false ## 4 4 171979 mule deer 2014-12-10 04:00:00 34895 MD13F0035 false ## 5 5 171980 mule deer 2014-12-10 16:00:00 34895 MD13F0035 false ## 6 6 170147 mule deer 2014-12-13 00:00:00 30261 MD14F0046 false ## sex currentAge latitude longitude currentCohort freq projectName ## 1 F 2.5 40.61487 -109.2107 adult 150.7638 &lt;NA&gt; ## 2 F 2.5 40.60612 -109.1469 adult 150.6706 &lt;NA&gt; ## 3 F 2.5 41.05850 -109.1184 adult 151.9882 &lt;NA&gt; ## 4 F 2.5 41.08347 -109.0206 adult 152.9788 &lt;NA&gt; ## 5 F 2.5 41.18861 -108.8705 adult 150.2661 &lt;NA&gt; ## 6 F 5.0 41.16767 -111.6087 adult 155.0224 &lt;NA&gt; ## captureUnit captureSubUnit birthYear realCaptureArea ## 1 South Slope Diamond Mtn 2013 Diamond ## 2 South Slope Diamond Mtn 2013 Diamond ## 3 South Slope Diamond Mtn 2013 Diamond ## 4 South Slope Diamond Mtn 2013 Diamond ## 5 South Slope Diamond Mtn 2013 Diamond ## 6 Oquirrh-Stansbury &lt;NA&gt; 2010 Pine Canyon First I need to format my full data into a base format: change datetime column to class POSIXct df = df %&gt;% # create a new column called &quot;dt&quot; (meaning &quot;datetime&quot;) mutate(dt = ymd_hms(dateYearAndJulian)) change mortality to logical class df = df %&gt;% mutate(mort = as.logical(mortality)) add a record ID for each record df = df %&gt;% mutate(rec_id = seq(1:nrow(df))) rename columns to a preferred format select only the needed columns. df = df %&gt;% select(rec_id, animal_id = uniqueID, species, sex, dt, # added y and x so I can remember which one is which lat_y = latitude, lon_x = longitude, cohort = currentCohort, birth_year = birthYear, mortality = mort, capture_unit = captureUnit, collar_id = collarID, collar_obj_id = collarObjectId, freq, proj = projectName) Lets see what the data looks like now head(df) ## rec_id animal_id species sex dt lat_y lon_x cohort ## 1 1 MD13F0035 mule deer F 2014-12-08 02:00:00 40.61487 -109.2107 adult ## 2 2 MD13F0035 mule deer F 2014-12-08 14:00:00 40.60612 -109.1469 adult ## 3 3 MD13F0035 mule deer F 2014-12-09 15:00:00 41.05850 -109.1184 adult ## 4 4 MD13F0035 mule deer F 2014-12-10 04:00:00 41.08347 -109.0206 adult ## 5 5 MD13F0035 mule deer F 2014-12-10 16:00:00 41.18861 -108.8705 adult ## 6 6 MD14F0046 mule deer F 2014-12-13 00:00:00 41.16767 -111.6087 adult ## birth_year mortality capture_unit collar_id collar_obj_id freq proj ## 1 2013 FALSE South Slope 34895 171976 150.7638 &lt;NA&gt; ## 2 2013 FALSE South Slope 34895 171977 150.6706 &lt;NA&gt; ## 3 2013 FALSE South Slope 34895 171978 151.9882 &lt;NA&gt; ## 4 2013 FALSE South Slope 34895 171979 152.9788 &lt;NA&gt; ## 5 2013 FALSE South Slope 34895 171980 150.2661 &lt;NA&gt; ## 6 2010 FALSE Oquirrh-Stansbury 30261 170147 155.0224 &lt;NA&gt; Looks great! 2.2.2 Sort into Different Datasets Now I can begin to sort into the different datasets for my final database structure 2.2.2.1 Individuals Dataset indiv = df %&gt;% select(animal_id, # this will be the primary key and a foreign key species, sex, birth_year, capture_unit) %&gt;% distinct() print(indiv) ## animal_id species sex birth_year capture_unit ## 1 MD13F0035 mule deer F 2013 South Slope ## 2 MD14F0046 mule deer F 2010 Oquirrh-Stansbury ## 3 MD11F0041 mule deer F 2009 Oquirrh-Stansbury ## 4 MD12U0015 mule deer U 2014 Oquirrh-Stansbury ## 5 MD14M0027 mule deer M 2011 Box Elder This table now shows our individual animals and their sex, species, birth year, and the management unit where they were captured. Now we can save this table for later. Ill save it as a .rds file so that it keeps the format and datatypes and so it takes up less disk space. saveRDS(indiv, &quot;Data/individual.rds&quot;) 2.2.2.2 Collar Dataset collar = df %&gt;% select(collar_id, # will be the primary key animal_id) %&gt;% # will be a foreign key distinct() # make sure all records are distinct print(collar) ## collar_id animal_id ## 1 34895 MD13F0035 ## 2 30261 MD14F0046 ## 3 34265 MD11F0041 ## 4 32680 MD12U0015 ## 5 33655 MD14M0027 Now we have a table showing our animals and their collar IDs. In this subset of data, these 5 individuals had the same collar the whole time. But in my real dataset, there are some animals that had more than one collar. So instead of collar_id being stored with the individuals table, collar is its own table. Ill also save this as a .rds file saveRDS(collar, &quot;Data/collar.rds&quot;) 2.2.2.3 Location Dataset gps = df %&gt;% # create a new column loc_id, a unique id for each location record mutate(loc_id = rep(1:nrow(df))) %&gt;% # sort into new df only with columns related to location data select(loc_id, # this will be the primary key animal_id, # this will be a foreign key dt, lat_y, lon_x) head(gps) ## loc_id animal_id dt lat_y lon_x ## 1 1 MD13F0035 2014-12-08 02:00:00 40.61487 -109.2107 ## 2 2 MD13F0035 2014-12-08 14:00:00 40.60612 -109.1469 ## 3 3 MD13F0035 2014-12-09 15:00:00 41.05850 -109.1184 ## 4 4 MD13F0035 2014-12-10 04:00:00 41.08347 -109.0206 ## 5 5 MD13F0035 2014-12-10 16:00:00 41.18861 -108.8705 ## 6 6 MD14F0046 2014-12-13 00:00:00 41.16767 -111.6087 For the Location datset, I also need to add a column for UTM x and UTM y. My study area is in Utah, which is UTM Zone 12N. To convert to UTM, I need to use the package sf. # Install Packages ---- install.packages(&quot;sf&quot;) # Load Packages library(sf) But because my (real) dataset of location data is very large, I want to convert this data piece by piece so R can handle it better. So instead of converting all at once, I will convert by year. To make this easier, Ill create a function to convert given latitude and longitude coordinates to UTM. # Function to Convert Lat Long to UTM Zone 12N---- convert_UTM = function(latlon_df){ utm_df = latlon_df %&gt;% # turns df into sf object with geometry st_as_sf(coords = c(&quot;lon_x&quot;, &quot;lat_y&quot;), crs = 4326) %&gt;% # WGS84 = EPSG 4326 # converts geometry to UTM 12N projection st_transform(crs = 32612) %&gt;% # UTM 12N = EPSG 32612 # creates a new column of x and y UTM 12N coordinates mutate(utm_x = st_coordinates(.)[, 1], utm_y = st_coordinates(.)[, 2]) %&gt;% # drops geometry column st_drop_geometry() return(utm_df) } # Convert to UTM ---- # My location dataset is very large # So I&#39;ll break it by year, convert, then bind together # make vector of range of dates dates = min(year(gps$dt)):max(year(gps$dt)) # empty dataframe for all UTM data utm = data.frame() # iterates over every date for(i in 1:length(dates)){ # temporary dataframe to store current year&#39;s utm utm_temp = gps %&gt;% # filter latlon dataframe by date filter(year(dt) == dates[i]) %&gt;% # convert to utm convert_UTM() # bind new utm to full utm utm = rbind(utm, utm_temp) } head(utm) ## loc_id animal_id dt utm_x utm_y ## 1 1 MD13F0035 2014-12-08 02:00:00 651359.4 4497544 ## 2 2 MD13F0035 2014-12-08 14:00:00 656774.1 4496684 ## 3 3 MD13F0035 2014-12-09 15:00:00 658105.5 4546956 ## 4 4 MD13F0035 2014-12-10 04:00:00 666261.1 4549910 ## 5 5 MD13F0035 2014-12-10 16:00:00 678585.6 4561881 ## 6 6 MD14F0046 2014-12-13 00:00:00 448935.4 4557549 After that years coordinates are converted, the data will be bound into a final dataframe and then joined with the gps table to make the final location dataset. # Join ---- # join gps with utm by the unique location id loc = inner_join(gps, utm, by = &quot;loc_id&quot;) %&gt;% # remove the extra columns (it creates &quot;animal_id.x&quot; etc) select(loc_id, animal_id = animal_id.x, dt = dt.x, lat_y, lon_x, utm_x, utm_y) head(loc) ## loc_id animal_id dt lat_y lon_x utm_x utm_y ## 1 1 MD13F0035 2014-12-08 02:00:00 40.61487 -109.2107 651359.4 4497544 ## 2 2 MD13F0035 2014-12-08 14:00:00 40.60612 -109.1469 656774.1 4496684 ## 3 3 MD13F0035 2014-12-09 15:00:00 41.05850 -109.1184 658105.5 4546956 ## 4 4 MD13F0035 2014-12-10 04:00:00 41.08347 -109.0206 666261.1 4549910 ## 5 5 MD13F0035 2014-12-10 16:00:00 41.18861 -108.8705 678585.6 4561881 ## 6 6 MD14F0046 2014-12-13 00:00:00 41.16767 -111.6087 448935.4 4557549 Lets save this table, again as a .rds file. # Save ---- saveRDS(loc, &quot;Data/location.rds&quot;) 2.2.2.4 Deployment Dataset # pull out distinct animal id id = df %&gt;% distinct(animal_id) # make empty dataframe deploy = data.frame() # iterate over every id for(i in 1:nrow(id)){ # make a temp df temp = df %&gt;% # pull out specific individual subset(animal_id == id[i, ]) %&gt;% # calculate start and end date for that individual, make into a column each mutate(start_dt = min(dt), end_dt = max(dt)) %&gt;% # shorten to just one record of the individual and its start and end date distinct(animal_id, # this is a foreign key start_dt, end_dt) # bind into the final deploy df deploy = rbind(deploy, temp) # remove the temp df rm(temp) } print(deploy) ## animal_id start_dt end_dt ## 1 MD13F0035 2014-12-08 02:00:00 2014-12-10 16:00:00 ## 2 MD14F0046 2014-12-13 00:00:00 2014-12-15 14:00:00 ## 3 MD11F0041 2014-12-12 00:00:00 2014-12-14 00:00:00 ## 4 MD12U0015 2014-12-15 11:00:00 2014-12-18 14:00:00 ## 5 MD14M0027 2014-04-03 10:22:29 2014-04-03 12:24:08 saveRDS(deploy, &quot;Data/deployment.rds&quot;) 2.3 RSQLite Now that Ive formatted all my datasets, its time to put them together in a database. To form this database, I will be working in with the package RSQLite # Install Packages---- install.packages(&quot;RSQLite&quot;) # Load Packages---- library(DBI) Once the package is installed and loaded, I can begin working in RSQLite. First, I need to create the database. # Establish Database Connection ---- db = dbConnect(drv = RSQLite::SQLite(), &quot;Data/barrier_proj.db&quot;) Then, I need to create the tables for all of my datasets. I need to create the individuals table first because it has no foreign key but its primary key (animal_id) is a foreign key for the other tables. dbExecute(db, &quot;CREATE TABLE individuals( animal_id char(9) NOT NULL PRIMARY KEY, species char(8), sex char(1) CHECK (sex IN (&#39;M&#39;, &#39;F&#39;, &#39;U&#39;)), birth_year integer, capture_unit varchar(20) );&quot;) I made animal_id of class char instead of varchar because every ID follows the same format: SPYYSXXXX SP = species abbreviation (MD or PR) YY = year captured S = sex XXXX = incremental unit For example, the 10th female mule deer captured in 2017 would have an id MD17F0010 Fortunately, both pronghorn and mule deer have the same number of characters (8), so I can make species a char class instead of varchar. Lets check that the table was built ok. Since I didnt put any data yet, it should be empty. dbGetQuery(conn = db, statement = &quot;SELECT * FROM individuals;&quot;) ## animal_id species sex birth_year capture_unit ## 1 MD13F0035 mule deer F 2013 South Slope ## 2 MD14F0046 mule deer F 2010 Oquirrh-Stansbury ## 3 MD11F0041 mule deer F 2009 Oquirrh-Stansbury ## 4 MD12U0015 mule deer U 2014 Oquirrh-Stansbury ## 5 MD14M0027 mule deer M 2011 Box Elder Awesome! Now I can create the other tables that use animal_id as a foreign key. dbExecute(db, &quot;CREATE TABLE collar( collar_id integer NOT NULL PRIMARY KEY, animal_id char(9), FOREIGN KEY (animal_id) REFERENCES individuals(animal_id) );&quot;) dbExecute(db, &quot;CREATE TABLE location( loc_id integer NOT NULL PRIMARY KEY, animal_id char(9), dt text, lat_y double, lon_x double, utm_x double, utm_y double, FOREIGN KEY (animal_id) REFERENCES individuals(animal_id) );&quot;) dbExecute(db, &quot;CREATE TABLE deployment( deploy_id INTEGER PRIMARY KEY AUTOINCREMENT, animal_id char(9), start_dt text, end_dt text, FOREIGN KEY (animal_id) REFERENCES individuals(animal_id) );&quot;) After the tables are created, all I need to do is import the data into the database. dbWriteTable(db, &quot;individuals&quot;, indiv, append = TRUE) dbWriteTable(db, &quot;collar&quot;, collar, append = TRUE) dbWriteTable(db, &quot;location&quot;, loc, append = TRUE) dbWriteTable(db, &quot;deployment&quot;, deploy, append = TRUE) And check that everything loaded in correctly dbGetQuery(conn = db, statement = &quot;SELECT * FROM individuals LIMIT 10;&quot;) ## animal_id species sex birth_year capture_unit ## 1 MD13F0035 mule deer F 2013 South Slope ## 2 MD14F0046 mule deer F 2010 Oquirrh-Stansbury ## 3 MD11F0041 mule deer F 2009 Oquirrh-Stansbury ## 4 MD12U0015 mule deer U 2014 Oquirrh-Stansbury ## 5 MD14M0027 mule deer M 2011 Box Elder dbGetQuery(conn = db, statement = &quot;SELECT * FROM collar LIMIT 10;&quot;) ## collar_id animal_id ## 1 30261 MD14F0046 ## 2 32680 MD12U0015 ## 3 33655 MD14M0027 ## 4 34265 MD11F0041 ## 5 34895 MD13F0035 dbGetQuery(conn = db, statement = &quot;SELECT * FROM location LIMIT 10;&quot;) ## loc_id animal_id dt lat_y lon_x utm_x utm_y ## 1 1 MD13F0035 1418004000.0 40.61487 -109.2107 651359.4 4497544 ## 2 2 MD13F0035 1418047200.0 40.60612 -109.1469 656774.1 4496684 ## 3 3 MD13F0035 1418137200.0 41.05850 -109.1184 658105.5 4546956 ## 4 4 MD13F0035 1418184000.0 41.08347 -109.0206 666261.1 4549910 ## 5 5 MD13F0035 1418227200.0 41.18861 -108.8705 678585.6 4561881 ## 6 6 MD14F0046 1418428800.0 41.16767 -111.6087 448935.4 4557549 ## 7 7 MD14F0046 1418472000.0 41.35899 -111.5288 455769.7 4578745 ## 8 8 MD14F0046 1418518800.0 40.88203 -112.2252 396772.7 4526384 ## 9 9 MD14F0046 1418608800.0 41.43313 -111.7143 440319.6 4587086 ## 10 10 MD14F0046 1418652000.0 41.45278 -111.3427 471376.1 4589079 dbGetQuery(conn = db, statement = &quot;SELECT * FROM deployment LIMIT 10;&quot;) ## deploy_id animal_id start_dt end_dt ## 1 1 MD13F0035 1418004000.0 1418227200.0 ## 2 2 MD14F0046 1418428800.0 1418652000.0 ## 3 3 MD11F0041 1418342400.0 1418515200.0 ## 4 4 MD12U0015 1418641200.0 1418911200.0 ## 5 5 MD14M0027 1396520549.0 1396527848.0 Hooray! My database has been created! "]]
